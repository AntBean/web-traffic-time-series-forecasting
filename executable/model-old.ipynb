{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T04:15:47.582272Z",
     "start_time": "2017-08-28T13:15:43.933309+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import numpy as np; np.seterr(invalid='ignore')\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T04:15:47.678810Z",
     "start_time": "2017-08-28T13:15:47.584485+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "parser = {\n",
    "    'data_path': '../data/wttsf/',\n",
    "    'train_file': 'train_1.csv',\n",
    "    'key_file': 'key_1.csv',\n",
    "    'intermediate_path': '../intermediate/',\n",
    "    'n_epoch': 4,\n",
    "    'future': 70,\n",
    "    'batch_size': 128,\n",
    "    'hidden_size': 256,\n",
    "    'log_every': 10,\n",
    "    'read_from_file': True,\n",
    "    'cuda': True,\n",
    "    'seed': 28082017,\n",
    "}\n",
    "args = argparse.Namespace(**parser)\n",
    "\n",
    "args.cuda = args.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T04:15:47.802907Z",
     "start_time": "2017-08-28T13:15:47.680994+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class DenseLSTMForecast(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(DenseLSTMForecast, self).__init__()\n",
    "        self.lstm1 = nn.LSTMCell(1, hidden_size, bias=False)\n",
    "        self.lstm2 = nn.LSTMCell(hidden_size+1, hidden_size, bias=False)\n",
    "        self.linear = nn.Linear(2*hidden_size+1, 1, bias=False)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, x, future=1):\n",
    "        o = []\n",
    "        tt = torch.cuda if args.cuda else torch\n",
    "        h1_t = Variable(tt.FloatTensor(x.size(0), self.hidden_size).zero_())\n",
    "        c1_t = Variable(tt.FloatTensor(x.size(0), self.hidden_size).zero_())\n",
    "        h2_t = Variable(tt.FloatTensor(x.size(0), self.hidden_size).zero_())\n",
    "        c2_t = Variable(tt.FloatTensor(x.size(0), self.hidden_size).zero_())\n",
    "        \n",
    "        for x_t in x.chunk(x.size(1), dim=1):\n",
    "            x_t = x_t.squeeze(dim=1)\n",
    "            h1_t, c1_t = self.lstm1(x_t, (h1_t, c1_t))\n",
    "            h1d_t = torch.cat([x_t, h1_t], dim=1)\n",
    "            h2_t, c2_t = self.lstm2(h1d_t, (h2_t, c2_t))\n",
    "            h2d_t = torch.cat([x_t, h1_t, h2_t], dim=1)\n",
    "            o_t = self.linear(h2d_t)\n",
    "            o.append(o_t)\n",
    "            \n",
    "        for i in range(future-1):\n",
    "            h1_t, c1_t = self.lstm1(o_t, (h1_t, c1_t))\n",
    "            h1d_t = torch.cat([x_t, h1_t], dim=1)\n",
    "            h2_t, c2_t = self.lstm2(h1d_t, (h2_t, c2_t))\n",
    "            h2d_t = torch.cat([x_t, h1_t, h2_t], dim=1)\n",
    "            o_t = self.linear(h2d_t)\n",
    "            o.append(o_t)\n",
    "\n",
    "        return torch.stack(o, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T04:15:47.857331Z",
     "start_time": "2017-08-28T13:15:47.805035+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def smape(y_pred, y_true):\n",
    "    raw_smape = np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred))\n",
    "    kaggle_smape = np.nan_to_num(raw_smape)\n",
    "    return np.mean(kaggle_smape) * 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T04:15:47.921971Z",
     "start_time": "2017-08-28T13:15:47.859581+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_scaled_data():\n",
    "    raw_data_file = os.path.join(args.intermediate_path,\n",
    "                                 'raw_data.pkl')\n",
    "    scaled_data_file = os.path.join(args.intermediate_path,\n",
    "                                    'scaled_data.pkl')\n",
    "    scaler_file = os.path.join(args.intermediate_path, 'scaler.pkl')\n",
    "    if not args.read_from_file:\n",
    "        data_df = pd.read_csv(os.path.join(args.data_path, args.train_file),\n",
    "                              index_col='Page')\n",
    "        raw_data = np.nan_to_num(data_df.values.astype('float32'))\n",
    "        data = np.log1p(raw_data)\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = np.swapaxes(scaler.fit_transform(\n",
    "                np.swapaxes(data, 0, 1)), 0, 1)\n",
    "        \n",
    "        with open(raw_data_file, 'wb') as f:\n",
    "            pickle.dump(raw_data, f)\n",
    "        with open(scaled_data_file, 'wb') as f:\n",
    "            pickle.dump(scaled_data, f)\n",
    "        with open(scaler_file, 'wb') as f:\n",
    "            pickle.dump(scaler, f)\n",
    "    else:\n",
    "        with open(raw_data_file, 'rb') as f:\n",
    "            raw_data = pickle.load(f)\n",
    "        with open(scaled_data_file, 'rb') as f:\n",
    "            scaled_data = pickle.load(f)\n",
    "        with open(scaler_file, 'rb') as f:\n",
    "            scaler = pickle.load(f)\n",
    "    return raw_data, scaled_data, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T04:15:48.031034Z",
     "start_time": "2017-08-28T13:15:47.924199+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_val_split(raw_data, scaled_data, scaler):\n",
    "    train_file = os.path.join(args.intermediate_path,\n",
    "                              'train_{}.pkl'.format(args.seed))\n",
    "    val_file = os.path.join(args.intermediate_path,\n",
    "                            'val_{}.pkl'.format(args.seed))\n",
    "    raw_val_file = os.path.join(args.intermediate_path,\n",
    "                                'raw_val_{}.pkl'.format(args.seed))\n",
    "    val_scaler_file = os.path.join(args.intermediate_path,\n",
    "                                   'val_scaler_{}.pkl'.format(args.seed))\n",
    "    if not args.read_from_file:\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=args.seed)\n",
    "        train_index, val_index = next(kf.split(scaled_data))\n",
    "        train = scaled_data[train_index]\n",
    "        val = scaled_data[val_index]\n",
    "        raw_val = raw_data[val_index]\n",
    "        val_scaler = StandardScaler()\n",
    "        val_scaler.mean_ = scaler.mean_[val_index]\n",
    "        val_scaler.scale_ = scaler.scale_[val_index]\n",
    "        \n",
    "        with open(train_file, 'wb') as f:\n",
    "            pickle.dump(train, f)\n",
    "        with open(val_file, 'wb') as f:\n",
    "            pickle.dump(val, f)\n",
    "        with open(raw_val_file, 'wb') as f:\n",
    "            pickle.dump(raw_val, f)\n",
    "        with open(val_scaler_file, 'wb') as f:\n",
    "            pickle.dump(val_scaler, f)\n",
    "    else:\n",
    "        with open(train_file, 'rb') as f:\n",
    "            train = pickle.load(f)\n",
    "        with open(val_file, 'rb') as f:\n",
    "            val = pickle.load(f)\n",
    "        with open(raw_val_file, 'rb') as f:\n",
    "            raw_val = pickle.load(f)\n",
    "        with open(val_scaler_file, 'rb') as f:\n",
    "            val_scaler = pickle.load(f)\n",
    "    return train, val, raw_val, val_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T04:15:48.080774Z",
     "start_time": "2017-08-28T13:15:48.033227+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def input_target_split(data, raw_data=None):\n",
    "    inputt = data[:, :-1]\n",
    "    if raw_data is None:\n",
    "        target = data[:, 1:]\n",
    "    else:\n",
    "        target = raw_data[:, 1:]\n",
    "    return inputt, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T04:15:48.128980Z",
     "start_time": "2017-08-28T13:15:48.083183+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer):\n",
    "    n_total = train_loss = 0\n",
    "    init_time = time.time()\n",
    "\n",
    "    for i, (inputt, target) in enumerate(train_loader):\n",
    "        if args.cuda:\n",
    "            inputt = inputt.cuda()\n",
    "            target = target.cuda()\n",
    "        inputt = Variable(inputt)\n",
    "        target = Variable(target)\n",
    "        \n",
    "        output = model(inputt)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        n_total += inputt.size(0)\n",
    "        train_loss += loss.data[0] * inputt.size(0)\n",
    "        \n",
    "        if i % args.log_every == 0:\n",
    "            print(\"   % Time: {:4.0f}s | Batch: {:3} | Loss: {:.4f}\"\n",
    "                  .format(time.time()-init_time, i+1, loss.data[0]))\n",
    "        \n",
    "    train_loss /= n_total\n",
    "    print(\"=\"*10 + \"\\n   % Time: {:4.0f}s | Train loss: {:.4f}\"\n",
    "          .format(time.time()-init_time, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T04:15:48.177824Z",
     "start_time": "2017-08-28T13:15:48.131130+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, val_scaler, val_target):\n",
    "    init_time = time.time()\n",
    "    \n",
    "    output_list = []\n",
    "    for inputt, _ in val_loader:\n",
    "        if args.cuda:\n",
    "            inputt = inputt.cuda()\n",
    "        inputt = Variable(inputt)\n",
    "        \n",
    "        output = model(inputt)\n",
    "        output_list.append(output.data.squeeze(2).cpu().numpy())\n",
    "        \n",
    "    output_all = np.concatenate(output_list, axis=0)\n",
    "    prediction = np.swapaxes(val_scaler.inverse_transform(\n",
    "            np.swapaxes(output_all, 0, 1)), 0, 1)\n",
    "    prediction = np.exp(prediction) - 1\n",
    "    prediction[prediction < 0.5] = 0\n",
    "    \n",
    "    val_loss = smape(prediction, val_target)\n",
    "    print(\"   % Time: {:4.0f}s | Val loss: {:.4f}\"\n",
    "          .format(time.time()-init_time, val_loss))\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T04:15:48.217023Z",
     "start_time": "2017-08-28T13:15:48.180099+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def forecast(scaled_data, model, scaler):\n",
    "    full_tensor = torch.from_numpy(scaled_data).unsqueeze(2)\n",
    "    empty_tensor = torch.zeros(full_tensor.size(0))\n",
    "    full_dataset = torch.utils.data.TensorDataset(full_tensor, empty_tensor)\n",
    "    data_loader = DataLoader(full_dataset, args.batch_size//2)\n",
    "    \n",
    "    output_list = []\n",
    "    for inputt, _ in data_loader:\n",
    "        if args.cuda:\n",
    "            inputt = inputt.cuda()\n",
    "        inputt = Variable(inputt)\n",
    "        output = model(inputt, args.future)\n",
    "        output_list.append(output.data.squeeze(2).cpu().numpy()\n",
    "                           [:, -args.future:])\n",
    "        \n",
    "    output_all = np.concatenate(output_list, axis=0)\n",
    "    prediction = np.swapaxes(scaler.inverse_transform(\n",
    "            np.swapaxes(output_all, 0, 1)), 0, 1)\n",
    "    prediction = np.exp(prediction) - 1\n",
    "    prediction[prediction < 0.5] = 0\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T04:15:48.268452Z",
     "start_time": "2017-08-28T13:15:48.218966+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, epoch, val_loss):\n",
    "    model_file = os.path.join(args.intermediate_path,\n",
    "                              \"model1_seed{}_epoch{}_loss_{:.4f}.pth\"\n",
    "                              .format(args.seed, epoch, val_loss))\n",
    "    torch.save(model.state_dict(), os.path.join(model_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T04:15:50.514316Z",
     "start_time": "2017-08-28T13:15:48.270591+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# scale data\n",
    "raw_data, scaled_data, scaler = get_scaled_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T04:15:50.846802Z",
     "start_time": "2017-08-28T13:15:50.516408+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# train/val split\n",
    "train_data, val_data, raw_val_data, val_scaler = train_val_split(\n",
    "    raw_data, scaled_data, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T04:15:50.853029Z",
     "start_time": "2017-08-28T13:15:50.849104+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# input/target split\n",
    "train_input, train_target = input_target_split(train_data)\n",
    "val_input, val_target = input_target_split(val_data, raw_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T04:15:50.896883Z",
     "start_time": "2017-08-28T13:15:50.855149+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert to tensors\n",
    "train_input_tensor = torch.from_numpy(train_input).unsqueeze(2)\n",
    "val_input_tensor = torch.from_numpy(val_input).unsqueeze(2)\n",
    "train_target_tensor = torch.from_numpy(train_target).unsqueeze(2)\n",
    "val_target_tensor = torch.zeros(val_input_tensor.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T04:15:50.945095Z",
     "start_time": "2017-08-28T13:15:50.898953+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# make dataset, data loader\n",
    "train_dataset = TensorDataset(train_input_tensor, train_target_tensor)\n",
    "val_dataset = TensorDataset(val_input_tensor, val_target_tensor)\n",
    "train_loader = DataLoader(train_dataset, args.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, args.batch_size//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T04:15:53.180234Z",
     "start_time": "2017-08-28T13:15:50.947393+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# init model\n",
    "model = DenseLSTMForecast(args.hidden_size)\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = MultiStepLR(optimizer, milestones=[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T04:15:53.185314Z",
     "start_time": "2017-08-28T13:15:53.182628+09:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load('../intermediate/model_seed28082017_epoch3_loss_26.6719.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T05:55:04.834710Z",
     "start_time": "2017-08-28T13:15:53.187500+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "=> EPOCH 1\n",
      "   % Time:    2s | Batch:   1 | Loss: 0.7173\n",
      "   % Time:   15s | Batch:  11 | Loss: 0.4828\n",
      "   % Time:   29s | Batch:  21 | Loss: 0.4438\n",
      "   % Time:   42s | Batch:  31 | Loss: 0.4698\n",
      "   % Time:   56s | Batch:  41 | Loss: 0.4398\n",
      "   % Time:   69s | Batch:  51 | Loss: 0.4599\n",
      "   % Time:   83s | Batch:  61 | Loss: 0.4321\n",
      "   % Time:   97s | Batch:  71 | Loss: 0.4290\n",
      "   % Time:  110s | Batch:  81 | Loss: 0.4578\n",
      "   % Time:  124s | Batch:  91 | Loss: 0.4580\n",
      "   % Time:  137s | Batch: 101 | Loss: 0.4145\n",
      "   % Time:  151s | Batch: 111 | Loss: 0.4480\n",
      "   % Time:  165s | Batch: 121 | Loss: 0.4450\n",
      "   % Time:  178s | Batch: 131 | Loss: 0.4241\n",
      "   % Time:  192s | Batch: 141 | Loss: 0.4470\n",
      "   % Time:  206s | Batch: 151 | Loss: 0.4420\n",
      "   % Time:  219s | Batch: 161 | Loss: 0.4262\n",
      "   % Time:  233s | Batch: 171 | Loss: 0.4139\n",
      "   % Time:  247s | Batch: 181 | Loss: 0.4290\n",
      "   % Time:  260s | Batch: 191 | Loss: 0.4300\n",
      "   % Time:  274s | Batch: 201 | Loss: 0.4339\n",
      "   % Time:  287s | Batch: 211 | Loss: 0.3985\n",
      "   % Time:  301s | Batch: 221 | Loss: 0.4022\n",
      "   % Time:  315s | Batch: 231 | Loss: 0.4193\n",
      "   % Time:  328s | Batch: 241 | Loss: 0.3804\n",
      "   % Time:  342s | Batch: 251 | Loss: 0.3791\n",
      "   % Time:  355s | Batch: 261 | Loss: 0.4437\n",
      "   % Time:  369s | Batch: 271 | Loss: 0.4408\n",
      "   % Time:  382s | Batch: 281 | Loss: 0.4076\n",
      "   % Time:  396s | Batch: 291 | Loss: 0.4316\n",
      "   % Time:  409s | Batch: 301 | Loss: 0.4187\n",
      "   % Time:  422s | Batch: 311 | Loss: 0.4110\n",
      "   % Time:  436s | Batch: 321 | Loss: 0.4288\n",
      "   % Time:  450s | Batch: 331 | Loss: 0.4189\n",
      "   % Time:  463s | Batch: 341 | Loss: 0.4367\n",
      "   % Time:  477s | Batch: 351 | Loss: 0.4043\n",
      "   % Time:  490s | Batch: 361 | Loss: 0.3812\n",
      "   % Time:  504s | Batch: 371 | Loss: 0.4129\n",
      "   % Time:  517s | Batch: 381 | Loss: 0.3934\n",
      "   % Time:  530s | Batch: 391 | Loss: 0.4349\n",
      "   % Time:  544s | Batch: 401 | Loss: 0.4276\n",
      "   % Time:  557s | Batch: 411 | Loss: 0.4074\n",
      "   % Time:  571s | Batch: 421 | Loss: 0.3959\n",
      "   % Time:  585s | Batch: 431 | Loss: 0.3752\n",
      "   % Time:  598s | Batch: 441 | Loss: 0.4011\n",
      "   % Time:  612s | Batch: 451 | Loss: 0.4068\n",
      "   % Time:  626s | Batch: 461 | Loss: 0.3921\n",
      "   % Time:  639s | Batch: 471 | Loss: 0.4070\n",
      "   % Time:  653s | Batch: 481 | Loss: 0.3885\n",
      "   % Time:  666s | Batch: 491 | Loss: 0.4108\n",
      "   % Time:  680s | Batch: 501 | Loss: 0.4436\n",
      "   % Time:  694s | Batch: 511 | Loss: 0.3986\n",
      "   % Time:  707s | Batch: 521 | Loss: 0.4111\n",
      "   % Time:  721s | Batch: 531 | Loss: 0.4112\n",
      "   % Time:  735s | Batch: 541 | Loss: 0.4208\n",
      "   % Time:  748s | Batch: 551 | Loss: 0.3964\n",
      "   % Time:  762s | Batch: 561 | Loss: 0.3476\n",
      "   % Time:  776s | Batch: 571 | Loss: 0.4010\n",
      "   % Time:  789s | Batch: 581 | Loss: 0.3940\n",
      "   % Time:  803s | Batch: 591 | Loss: 0.3740\n",
      "   % Time:  816s | Batch: 601 | Loss: 0.3961\n",
      "   % Time:  830s | Batch: 611 | Loss: 0.3837\n",
      "   % Time:  843s | Batch: 621 | Loss: 0.3844\n",
      "   % Time:  857s | Batch: 631 | Loss: 0.3844\n",
      "   % Time:  870s | Batch: 641 | Loss: 0.3775\n",
      "   % Time:  884s | Batch: 651 | Loss: 0.3903\n",
      "   % Time:  898s | Batch: 661 | Loss: 0.3841\n",
      "   % Time:  911s | Batch: 671 | Loss: 0.3952\n",
      "   % Time:  924s | Batch: 681 | Loss: 0.3968\n",
      "   % Time:  938s | Batch: 691 | Loss: 0.4153\n",
      "   % Time:  951s | Batch: 701 | Loss: 0.3833\n",
      "   % Time:  965s | Batch: 711 | Loss: 0.3714\n",
      "   % Time:  978s | Batch: 721 | Loss: 0.3601\n",
      "   % Time:  992s | Batch: 731 | Loss: 0.3910\n",
      "   % Time: 1005s | Batch: 741 | Loss: 0.4004\n",
      "   % Time: 1019s | Batch: 751 | Loss: 0.4046\n",
      "   % Time: 1032s | Batch: 761 | Loss: 0.4117\n",
      "   % Time: 1046s | Batch: 771 | Loss: 0.3498\n",
      "   % Time: 1059s | Batch: 781 | Loss: 0.3985\n",
      "   % Time: 1072s | Batch: 791 | Loss: 0.3748\n",
      "   % Time: 1086s | Batch: 801 | Loss: 0.3861\n",
      "   % Time: 1100s | Batch: 811 | Loss: 0.3369\n",
      "   % Time: 1113s | Batch: 821 | Loss: 0.3795\n",
      "   % Time: 1127s | Batch: 831 | Loss: 0.4035\n",
      "   % Time: 1140s | Batch: 841 | Loss: 0.3626\n",
      "   % Time: 1154s | Batch: 851 | Loss: 0.3804\n",
      "   % Time: 1167s | Batch: 861 | Loss: 0.4096\n",
      "   % Time: 1181s | Batch: 871 | Loss: 0.3755\n",
      "   % Time: 1195s | Batch: 881 | Loss: 0.3904\n",
      "   % Time: 1208s | Batch: 891 | Loss: 0.3738\n",
      "   % Time: 1222s | Batch: 901 | Loss: 0.3560\n",
      "==========\n",
      "   % Time: 1230s | Train loss: 0.4086\n",
      "   % Time:  234s | Val loss: 27.4805\n",
      "==========\n",
      "=> EPOCH 2\n",
      "   % Time:    1s | Batch:   1 | Loss: 0.3780\n",
      "   % Time:   15s | Batch:  11 | Loss: 0.3933\n",
      "   % Time:   28s | Batch:  21 | Loss: 0.3958\n",
      "   % Time:   42s | Batch:  31 | Loss: 0.3858\n",
      "   % Time:   56s | Batch:  41 | Loss: 0.3708\n",
      "   % Time:   69s | Batch:  51 | Loss: 0.3949\n",
      "   % Time:   83s | Batch:  61 | Loss: 0.3949\n",
      "   % Time:   96s | Batch:  71 | Loss: 0.3854\n",
      "   % Time:  109s | Batch:  81 | Loss: 0.3900\n",
      "   % Time:  123s | Batch:  91 | Loss: 0.4098\n",
      "   % Time:  136s | Batch: 101 | Loss: 0.3812\n",
      "   % Time:  150s | Batch: 111 | Loss: 0.3829\n",
      "   % Time:  163s | Batch: 121 | Loss: 0.4009\n",
      "   % Time:  177s | Batch: 131 | Loss: 0.3891\n",
      "   % Time:  190s | Batch: 141 | Loss: 0.4143\n",
      "   % Time:  204s | Batch: 151 | Loss: 0.4005\n",
      "   % Time:  217s | Batch: 161 | Loss: 0.3806\n",
      "   % Time:  230s | Batch: 171 | Loss: 0.3810\n",
      "   % Time:  244s | Batch: 181 | Loss: 0.3980\n",
      "   % Time:  257s | Batch: 191 | Loss: 0.4086\n",
      "   % Time:  271s | Batch: 201 | Loss: 0.3941\n",
      "   % Time:  284s | Batch: 211 | Loss: 0.3910\n",
      "   % Time:  298s | Batch: 221 | Loss: 0.3893\n",
      "   % Time:  311s | Batch: 231 | Loss: 0.3582\n",
      "   % Time:  324s | Batch: 241 | Loss: 0.3877\n",
      "   % Time:  338s | Batch: 251 | Loss: 0.3580\n",
      "   % Time:  351s | Batch: 261 | Loss: 0.3647\n",
      "   % Time:  365s | Batch: 271 | Loss: 0.3740\n",
      "   % Time:  378s | Batch: 281 | Loss: 0.3799\n",
      "   % Time:  392s | Batch: 291 | Loss: 0.4023\n",
      "   % Time:  405s | Batch: 301 | Loss: 0.3691\n",
      "   % Time:  419s | Batch: 311 | Loss: 0.4054\n",
      "   % Time:  432s | Batch: 321 | Loss: 0.3478\n",
      "   % Time:  446s | Batch: 331 | Loss: 0.3647\n",
      "   % Time:  459s | Batch: 341 | Loss: 0.3758\n",
      "   % Time:  472s | Batch: 351 | Loss: 0.3698\n",
      "   % Time:  486s | Batch: 361 | Loss: 0.4042\n",
      "   % Time:  499s | Batch: 371 | Loss: 0.3775\n",
      "   % Time:  512s | Batch: 381 | Loss: 0.3818\n",
      "   % Time:  526s | Batch: 391 | Loss: 0.3810\n",
      "   % Time:  539s | Batch: 401 | Loss: 0.3647\n",
      "   % Time:  552s | Batch: 411 | Loss: 0.4061\n",
      "   % Time:  566s | Batch: 421 | Loss: 0.3625\n",
      "   % Time:  580s | Batch: 431 | Loss: 0.3925\n",
      "   % Time:  593s | Batch: 441 | Loss: 0.3668\n",
      "   % Time:  607s | Batch: 451 | Loss: 0.3820\n",
      "   % Time:  621s | Batch: 461 | Loss: 0.3739\n",
      "   % Time:  634s | Batch: 471 | Loss: 0.3728\n",
      "   % Time:  648s | Batch: 481 | Loss: 0.3768\n",
      "   % Time:  662s | Batch: 491 | Loss: 0.3430\n",
      "   % Time:  675s | Batch: 501 | Loss: 0.3684\n",
      "   % Time:  689s | Batch: 511 | Loss: 0.3822\n",
      "   % Time:  703s | Batch: 521 | Loss: 0.3878\n",
      "   % Time:  716s | Batch: 531 | Loss: 0.3690\n",
      "   % Time:  730s | Batch: 541 | Loss: 0.3574\n",
      "   % Time:  743s | Batch: 551 | Loss: 0.4052\n",
      "   % Time:  757s | Batch: 561 | Loss: 0.3729\n",
      "   % Time:  771s | Batch: 571 | Loss: 0.3721\n",
      "   % Time:  784s | Batch: 581 | Loss: 0.3612\n",
      "   % Time:  798s | Batch: 591 | Loss: 0.4038\n",
      "   % Time:  811s | Batch: 601 | Loss: 0.4126\n",
      "   % Time:  825s | Batch: 611 | Loss: 0.4021\n",
      "   % Time:  838s | Batch: 621 | Loss: 0.3742\n",
      "   % Time:  852s | Batch: 631 | Loss: 0.3814\n",
      "   % Time:  865s | Batch: 641 | Loss: 0.3821\n",
      "   % Time:  879s | Batch: 651 | Loss: 0.3969\n",
      "   % Time:  893s | Batch: 661 | Loss: 0.4182\n",
      "   % Time:  906s | Batch: 671 | Loss: 0.3967\n",
      "   % Time:  920s | Batch: 681 | Loss: 0.3751\n",
      "   % Time:  934s | Batch: 691 | Loss: 0.3918\n",
      "   % Time:  947s | Batch: 701 | Loss: 0.3888\n",
      "   % Time:  961s | Batch: 711 | Loss: 0.3789\n",
      "   % Time:  975s | Batch: 721 | Loss: 0.3978\n",
      "   % Time:  988s | Batch: 731 | Loss: 0.4108\n",
      "   % Time: 1002s | Batch: 741 | Loss: 0.3533\n",
      "   % Time: 1016s | Batch: 751 | Loss: 0.3749\n",
      "   % Time: 1029s | Batch: 761 | Loss: 0.3876\n",
      "   % Time: 1043s | Batch: 771 | Loss: 0.3855\n",
      "   % Time: 1056s | Batch: 781 | Loss: 0.4087\n",
      "   % Time: 1070s | Batch: 791 | Loss: 0.3753\n",
      "   % Time: 1083s | Batch: 801 | Loss: 0.3626\n",
      "   % Time: 1097s | Batch: 811 | Loss: 0.4075\n",
      "   % Time: 1110s | Batch: 821 | Loss: 0.3840\n",
      "   % Time: 1124s | Batch: 831 | Loss: 0.3787\n",
      "   % Time: 1138s | Batch: 841 | Loss: 0.3697\n",
      "   % Time: 1151s | Batch: 851 | Loss: 0.3905\n",
      "   % Time: 1165s | Batch: 861 | Loss: 0.3953\n",
      "   % Time: 1178s | Batch: 871 | Loss: 0.3750\n",
      "   % Time: 1192s | Batch: 881 | Loss: 0.3954\n",
      "   % Time: 1205s | Batch: 891 | Loss: 0.3767\n",
      "   % Time: 1219s | Batch: 901 | Loss: 0.4209\n",
      "==========\n",
      "   % Time: 1227s | Train loss: 0.3841\n",
      "   % Time:  229s | Val loss: 27.1566\n",
      "==========\n",
      "=> EPOCH 3\n",
      "   % Time:    1s | Batch:   1 | Loss: 0.3707\n",
      "   % Time:   15s | Batch:  11 | Loss: 0.3910\n",
      "   % Time:   28s | Batch:  21 | Loss: 0.3844\n",
      "   % Time:   42s | Batch:  31 | Loss: 0.3815\n",
      "   % Time:   55s | Batch:  41 | Loss: 0.3728\n",
      "   % Time:   69s | Batch:  51 | Loss: 0.3770\n",
      "   % Time:   82s | Batch:  61 | Loss: 0.3701\n",
      "   % Time:   96s | Batch:  71 | Loss: 0.3966\n",
      "   % Time:  109s | Batch:  81 | Loss: 0.3826\n",
      "   % Time:  123s | Batch:  91 | Loss: 0.3793\n",
      "   % Time:  137s | Batch: 101 | Loss: 0.3613\n",
      "   % Time:  150s | Batch: 111 | Loss: 0.3825\n",
      "   % Time:  164s | Batch: 121 | Loss: 0.4036\n",
      "   % Time:  178s | Batch: 131 | Loss: 0.3571\n",
      "   % Time:  191s | Batch: 141 | Loss: 0.3836\n",
      "   % Time:  205s | Batch: 151 | Loss: 0.3997\n",
      "   % Time:  218s | Batch: 161 | Loss: 0.4062\n",
      "   % Time:  232s | Batch: 171 | Loss: 0.3666\n",
      "   % Time:  245s | Batch: 181 | Loss: 0.3837\n",
      "   % Time:  259s | Batch: 191 | Loss: 0.3821\n",
      "   % Time:  272s | Batch: 201 | Loss: 0.3582\n",
      "   % Time:  286s | Batch: 211 | Loss: 0.3610\n",
      "   % Time:  299s | Batch: 221 | Loss: 0.4461\n",
      "   % Time:  313s | Batch: 231 | Loss: 0.3573\n",
      "   % Time:  326s | Batch: 241 | Loss: 0.3620\n",
      "   % Time:  340s | Batch: 251 | Loss: 0.3559\n",
      "   % Time:  353s | Batch: 261 | Loss: 0.4038\n",
      "   % Time:  367s | Batch: 271 | Loss: 0.4451\n",
      "   % Time:  380s | Batch: 281 | Loss: 0.3672\n",
      "   % Time:  394s | Batch: 291 | Loss: 0.3990\n",
      "   % Time:  408s | Batch: 301 | Loss: 0.3786\n",
      "   % Time:  421s | Batch: 311 | Loss: 0.3564\n",
      "   % Time:  435s | Batch: 321 | Loss: 0.3828\n",
      "   % Time:  448s | Batch: 331 | Loss: 0.3959\n",
      "   % Time:  462s | Batch: 341 | Loss: 0.4055\n",
      "   % Time:  476s | Batch: 351 | Loss: 0.3525\n",
      "   % Time:  489s | Batch: 361 | Loss: 0.3668\n",
      "   % Time:  503s | Batch: 371 | Loss: 0.3956\n",
      "   % Time:  517s | Batch: 381 | Loss: 0.3915\n",
      "   % Time:  530s | Batch: 391 | Loss: 0.3902\n",
      "   % Time:  543s | Batch: 401 | Loss: 0.3900\n",
      "   % Time:  557s | Batch: 411 | Loss: 0.3885\n",
      "   % Time:  570s | Batch: 421 | Loss: 0.4099\n",
      "   % Time:  584s | Batch: 431 | Loss: 0.4074\n",
      "   % Time:  598s | Batch: 441 | Loss: 0.3803\n",
      "   % Time:  611s | Batch: 451 | Loss: 0.3893\n",
      "   % Time:  625s | Batch: 461 | Loss: 0.3344\n",
      "   % Time:  639s | Batch: 471 | Loss: 0.3886\n",
      "   % Time:  652s | Batch: 481 | Loss: 0.3578\n",
      "   % Time:  666s | Batch: 491 | Loss: 0.3826\n",
      "   % Time:  680s | Batch: 501 | Loss: 0.3770\n",
      "   % Time:  693s | Batch: 511 | Loss: 0.3523\n",
      "   % Time:  707s | Batch: 521 | Loss: 0.3871\n",
      "   % Time:  720s | Batch: 531 | Loss: 0.3729\n",
      "   % Time:  734s | Batch: 541 | Loss: 0.3796\n",
      "   % Time:  747s | Batch: 551 | Loss: 0.3677\n",
      "   % Time:  761s | Batch: 561 | Loss: 0.3504\n",
      "   % Time:  774s | Batch: 571 | Loss: 0.3891\n",
      "   % Time:  788s | Batch: 581 | Loss: 0.3719\n",
      "   % Time:  801s | Batch: 591 | Loss: 0.3689\n",
      "   % Time:  815s | Batch: 601 | Loss: 0.3565\n",
      "   % Time:  828s | Batch: 611 | Loss: 0.3728\n",
      "   % Time:  842s | Batch: 621 | Loss: 0.3712\n",
      "   % Time:  855s | Batch: 631 | Loss: 0.3722\n",
      "   % Time:  868s | Batch: 641 | Loss: 0.3416\n",
      "   % Time:  882s | Batch: 651 | Loss: 0.4047\n",
      "   % Time:  895s | Batch: 661 | Loss: 0.3689\n",
      "   % Time:  909s | Batch: 671 | Loss: 0.4060\n",
      "   % Time:  922s | Batch: 681 | Loss: 0.3916\n",
      "   % Time:  936s | Batch: 691 | Loss: 0.3861\n",
      "   % Time:  949s | Batch: 701 | Loss: 0.3899\n",
      "   % Time:  962s | Batch: 711 | Loss: 0.3929\n",
      "   % Time:  976s | Batch: 721 | Loss: 0.3807\n",
      "   % Time:  989s | Batch: 731 | Loss: 0.3764\n",
      "   % Time: 1003s | Batch: 741 | Loss: 0.3686\n",
      "   % Time: 1016s | Batch: 751 | Loss: 0.3559\n",
      "   % Time: 1030s | Batch: 761 | Loss: 0.3702\n",
      "   % Time: 1044s | Batch: 771 | Loss: 0.3912\n",
      "   % Time: 1057s | Batch: 781 | Loss: 0.3780\n",
      "   % Time: 1071s | Batch: 791 | Loss: 0.3796\n",
      "   % Time: 1084s | Batch: 801 | Loss: 0.3997\n",
      "   % Time: 1098s | Batch: 811 | Loss: 0.3758\n",
      "   % Time: 1112s | Batch: 821 | Loss: 0.3752\n",
      "   % Time: 1125s | Batch: 831 | Loss: 0.3903\n",
      "   % Time: 1139s | Batch: 841 | Loss: 0.4126\n",
      "   % Time: 1153s | Batch: 851 | Loss: 0.3781\n",
      "   % Time: 1166s | Batch: 861 | Loss: 0.3782\n",
      "   % Time: 1180s | Batch: 871 | Loss: 0.4099\n",
      "   % Time: 1193s | Batch: 881 | Loss: 0.3870\n",
      "   % Time: 1207s | Batch: 891 | Loss: 0.3780\n",
      "   % Time: 1221s | Batch: 901 | Loss: 0.3810\n",
      "==========\n",
      "   % Time: 1229s | Train loss: 0.3796\n",
      "   % Time:  232s | Val loss: 26.9414\n",
      "==========\n",
      "=> EPOCH 4\n",
      "   % Time:    1s | Batch:   1 | Loss: 0.3714\n",
      "   % Time:   16s | Batch:  11 | Loss: 0.3950\n",
      "   % Time:   31s | Batch:  21 | Loss: 0.3587\n",
      "   % Time:   46s | Batch:  31 | Loss: 0.3794\n",
      "   % Time:   60s | Batch:  41 | Loss: 0.4026\n",
      "   % Time:   75s | Batch:  51 | Loss: 0.3671\n",
      "   % Time:   90s | Batch:  61 | Loss: 0.3976\n",
      "   % Time:  105s | Batch:  71 | Loss: 0.3574\n",
      "   % Time:  119s | Batch:  81 | Loss: 0.3924\n",
      "   % Time:  134s | Batch:  91 | Loss: 0.3368\n",
      "   % Time:  149s | Batch: 101 | Loss: 0.3807\n",
      "   % Time:  164s | Batch: 111 | Loss: 0.3795\n",
      "   % Time:  179s | Batch: 121 | Loss: 0.3885\n",
      "   % Time:  193s | Batch: 131 | Loss: 0.3669\n",
      "   % Time:  208s | Batch: 141 | Loss: 0.3697\n",
      "   % Time:  223s | Batch: 151 | Loss: 0.3957\n",
      "   % Time:  238s | Batch: 161 | Loss: 0.4043\n",
      "   % Time:  253s | Batch: 171 | Loss: 0.3455\n",
      "   % Time:  268s | Batch: 181 | Loss: 0.3967\n",
      "   % Time:  283s | Batch: 191 | Loss: 0.3696\n",
      "   % Time:  297s | Batch: 201 | Loss: 0.3754\n",
      "   % Time:  312s | Batch: 211 | Loss: 0.4007\n",
      "   % Time:  327s | Batch: 221 | Loss: 0.3325\n",
      "   % Time:  341s | Batch: 231 | Loss: 0.3838\n",
      "   % Time:  356s | Batch: 241 | Loss: 0.3893\n",
      "   % Time:  371s | Batch: 251 | Loss: 0.3885\n",
      "   % Time:  385s | Batch: 261 | Loss: 0.4118\n",
      "   % Time:  400s | Batch: 271 | Loss: 0.3970\n",
      "   % Time:  415s | Batch: 281 | Loss: 0.3801\n",
      "   % Time:  429s | Batch: 291 | Loss: 0.3658\n",
      "   % Time:  444s | Batch: 301 | Loss: 0.3979\n",
      "   % Time:  459s | Batch: 311 | Loss: 0.3998\n",
      "   % Time:  474s | Batch: 321 | Loss: 0.3781\n",
      "   % Time:  488s | Batch: 331 | Loss: 0.4060\n",
      "   % Time:  503s | Batch: 341 | Loss: 0.3632\n",
      "   % Time:  518s | Batch: 351 | Loss: 0.4005\n",
      "   % Time:  533s | Batch: 361 | Loss: 0.3883\n",
      "   % Time:  547s | Batch: 371 | Loss: 0.3481\n",
      "   % Time:  562s | Batch: 381 | Loss: 0.3658\n",
      "   % Time:  577s | Batch: 391 | Loss: 0.3789\n",
      "   % Time:  592s | Batch: 401 | Loss: 0.4036\n",
      "   % Time:  607s | Batch: 411 | Loss: 0.3879\n",
      "   % Time:  621s | Batch: 421 | Loss: 0.3974\n",
      "   % Time:  636s | Batch: 431 | Loss: 0.3767\n",
      "   % Time:  651s | Batch: 441 | Loss: 0.3658\n",
      "   % Time:  666s | Batch: 451 | Loss: 0.3502\n",
      "   % Time:  680s | Batch: 461 | Loss: 0.3768\n",
      "   % Time:  695s | Batch: 471 | Loss: 0.3834\n",
      "   % Time:  710s | Batch: 481 | Loss: 0.3628\n",
      "   % Time:  725s | Batch: 491 | Loss: 0.3611\n",
      "   % Time:  740s | Batch: 501 | Loss: 0.3762\n",
      "   % Time:  754s | Batch: 511 | Loss: 0.3556\n",
      "   % Time:  769s | Batch: 521 | Loss: 0.3817\n",
      "   % Time:  784s | Batch: 531 | Loss: 0.3993\n",
      "   % Time:  799s | Batch: 541 | Loss: 0.3795\n",
      "   % Time:  813s | Batch: 551 | Loss: 0.4093\n",
      "   % Time:  828s | Batch: 561 | Loss: 0.3905\n",
      "   % Time:  843s | Batch: 571 | Loss: 0.3538\n",
      "   % Time:  858s | Batch: 581 | Loss: 0.3637\n",
      "   % Time:  873s | Batch: 591 | Loss: 0.3729\n",
      "   % Time:  888s | Batch: 601 | Loss: 0.3962\n",
      "   % Time:  903s | Batch: 611 | Loss: 0.4097\n",
      "   % Time:  918s | Batch: 621 | Loss: 0.3559\n",
      "   % Time:  933s | Batch: 631 | Loss: 0.3669\n",
      "   % Time:  947s | Batch: 641 | Loss: 0.3363\n",
      "   % Time:  962s | Batch: 651 | Loss: 0.3588\n",
      "   % Time:  977s | Batch: 661 | Loss: 0.4044\n",
      "   % Time:  992s | Batch: 671 | Loss: 0.3932\n",
      "   % Time: 1007s | Batch: 681 | Loss: 0.3934\n",
      "   % Time: 1022s | Batch: 691 | Loss: 0.3711\n",
      "   % Time: 1037s | Batch: 701 | Loss: 0.3852\n",
      "   % Time: 1052s | Batch: 711 | Loss: 0.3763\n",
      "   % Time: 1067s | Batch: 721 | Loss: 0.3584\n",
      "   % Time: 1081s | Batch: 731 | Loss: 0.3818\n",
      "   % Time: 1096s | Batch: 741 | Loss: 0.3682\n",
      "   % Time: 1111s | Batch: 751 | Loss: 0.3822\n",
      "   % Time: 1126s | Batch: 761 | Loss: 0.3820\n",
      "   % Time: 1140s | Batch: 771 | Loss: 0.3905\n",
      "   % Time: 1155s | Batch: 781 | Loss: 0.3855\n",
      "   % Time: 1170s | Batch: 791 | Loss: 0.3769\n",
      "   % Time: 1184s | Batch: 801 | Loss: 0.3827\n",
      "   % Time: 1199s | Batch: 811 | Loss: 0.3661\n",
      "   % Time: 1213s | Batch: 821 | Loss: 0.3663\n",
      "   % Time: 1228s | Batch: 831 | Loss: 0.3485\n",
      "   % Time: 1243s | Batch: 841 | Loss: 0.3898\n",
      "   % Time: 1257s | Batch: 851 | Loss: 0.3831\n",
      "   % Time: 1272s | Batch: 861 | Loss: 0.4072\n",
      "   % Time: 1286s | Batch: 871 | Loss: 0.3819\n",
      "   % Time: 1301s | Batch: 881 | Loss: 0.3766\n",
      "   % Time: 1316s | Batch: 891 | Loss: 0.3814\n",
      "   % Time: 1331s | Batch: 901 | Loss: 0.3935\n",
      "==========\n",
      "   % Time: 1340s | Train loss: 0.3785\n",
      "   % Time:  231s | Val loss: 26.8477\n"
     ]
    }
   ],
   "source": [
    "if 1 == 1:\n",
    "    for epoch in range(1, args.n_epoch+1):\n",
    "        scheduler.step()\n",
    "        print(\"=\"*10 + \"\\n=> EPOCH {}\".format(epoch))\n",
    "        train(train_loader, model, criterion, optimizer)\n",
    "        val_loss = validate(val_loader, model, val_scaler, val_target)\n",
    "        save_model(model, epoch, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T06:16:36.650950Z",
     "start_time": "2017-08-28T14:55:04.836979+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prediction = forecast(scaled_data, model, scaler)\n",
    "prediction_file = os.path.join(args.intermediate_path,\n",
    "                               'prediction1_seed{}.pkl'.format(args.seed))\n",
    "\n",
    "with open(prediction_file, 'wb') as f:\n",
    "    pickle.dump(prediction, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T06:16:37.568065Z",
     "start_time": "2017-08-28T15:16:36.653114+09:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.05631600e+06,   2.07948800e+06,   2.38792300e+06,\n",
       "          2.95928600e+06,   1.35176400e+06,   2.93916000e+05,\n",
       "          2.25000000e+04,   2.51700000e+03,   5.60000000e+02,\n",
       "          1.40000000e+02]),\n",
       " array([  0.        ,   1.71491146,   3.42982292,   5.14473438,\n",
       "          6.85964584,   8.5745573 ,  10.28946877,  12.00438023,\n",
       "         13.71929169,  15.43420315,  17.14911461]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAD8CAYAAACyyUlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3QwTSVK3/w+hoxejUv1jQQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff549f283c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(np.log1p(prediction.flatten()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pydata]",
   "language": "python",
   "name": "conda-env-pydata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
